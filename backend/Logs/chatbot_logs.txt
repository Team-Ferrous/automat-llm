2025-11-09 01:07:11,819 - INFO - HTTP Request: GET https://enb5w7lzsiggptazuakxug.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 404 Not Found"
2025-11-09 01:11:47,902 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:11:48,788 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:43:54,768 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:43:55,683 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:45:02,453 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:45:03,140 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:45:35,578 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:45:36,199 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:47:58,088 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:47:58,724 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:49:00,086 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:49:01,048 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:49:01,149 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-09 01:49:08,527 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-09 01:49:08,527 - INFO - NumExpr defaulting to 8 threads.
2025-11-09 01:49:10,166 - INFO - Use pytorch device_name: cpu
2025-11-09 01:49:10,166 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-09 01:51:32,668 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:51:33,270 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:51:33,359 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-09 01:51:35,628 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-09 01:51:35,628 - INFO - NumExpr defaulting to 8 threads.
2025-11-09 01:51:36,352 - INFO - Use pytorch device_name: cpu
2025-11-09 01:51:36,352 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-09 01:51:38,245 - INFO - Loading faiss with AVX2 support.
2025-11-09 01:51:38,508 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-09 01:51:38,515 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-09 01:53:03,147 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:53:03,922 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:53:04,005 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-09 01:53:06,228 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-09 01:53:06,229 - INFO - NumExpr defaulting to 8 threads.
2025-11-09 01:53:06,941 - INFO - Use pytorch device_name: cpu
2025-11-09 01:53:06,942 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-09 01:53:08,395 - INFO - Loading faiss with AVX2 support.
2025-11-09 01:53:08,416 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-09 01:53:08,422 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-09 01:54:19,700 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:54:20,365 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:54:20,452 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-09 01:54:20,912 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-09 01:54:21,418 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-09 01:54:23,836 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-09 01:54:23,836 - INFO - NumExpr defaulting to 8 threads.
2025-11-09 01:54:24,584 - INFO - Use pytorch device_name: cpu
2025-11-09 01:54:24,584 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-09 01:54:25,959 - INFO - Loading faiss with AVX2 support.
2025-11-09 01:54:25,981 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-09 01:54:25,987 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-09 01:54:26,764 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:26,842 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:26,923 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,005 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,083 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,166 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,240 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,317 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,400 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-09 01:54:27,484 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 19:43:04,695 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-12 19:43:05,654 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-12 19:43:05,866 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-12 19:43:06,440 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-12 19:43:07,028 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-12 20:27:31,913 - INFO - HTTP Request: GET https://enb5w7lzsiggptazuakxug.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 404 Not Found"
2025-11-12 20:35:32,552 - INFO - HTTP Request: GET https://enb5w7lzsiggptazuakxug.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 404 Not Found"
2025-11-12 20:37:05,906 - INFO - HTTP Request: GET https://enb5w7lzsiggptazuakxug.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 404 Not Found"
2025-11-12 20:37:36,879 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-12 20:37:37,583 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-12 20:38:03,866 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-12 20:38:04,414 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-12 20:38:04,514 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-12 20:38:05,052 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-12 20:38:05,633 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-12 20:38:08,831 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-12 20:38:08,831 - INFO - NumExpr defaulting to 8 threads.
2025-11-12 20:38:09,873 - INFO - Use pytorch device_name: cpu
2025-11-12 20:38:09,873 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-12 20:38:12,349 - INFO - Loading faiss with AVX2 support.
2025-11-12 20:38:12,634 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-12 20:38:12,641 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-12 20:38:13,104 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,190 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,271 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,355 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,437 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,520 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,598 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,680 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,772 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-12 20:38:13,855 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:15,550 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 13:56:16,576 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 13:56:16,768 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 13:56:17,262 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 13:56:17,805 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 13:56:25,213 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 13:56:25,215 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 13:56:26,892 - INFO - Use pytorch device_name: cpu
2025-11-13 13:56:26,892 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 13:56:28,731 - INFO - Loading faiss with AVX2 support.
2025-11-13 13:56:29,000 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 13:56:29,006 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 13:56:29,408 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,497 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,577 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,657 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,736 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,818 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,893 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:29,977 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:30,057 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 13:56:30,138 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:18:32,459 - ERROR - Error generating response: Input length of input_ids is 3810, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.
2025-11-13 14:33:45,899 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 14:33:46,838 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 14:33:46,931 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 14:33:47,501 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 14:33:48,105 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 14:33:50,830 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 14:33:50,830 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 14:33:51,747 - INFO - Use pytorch device_name: cpu
2025-11-13 14:33:51,747 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 14:33:53,347 - INFO - Loading faiss with AVX2 support.
2025-11-13 14:33:53,372 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 14:33:53,378 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 14:33:53,796 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:53,878 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:53,958 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,037 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,116 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,201 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,281 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,364 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,452 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,534 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 14:33:54,838 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-13 14:33:58,674 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-13 14:33:58,682 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-13 14:33:58,690 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-13 14:43:01,497 - ERROR - Error generating response: 'NoneType' object has no attribute 'invoke'
2025-11-13 14:43:03,361 - ERROR - Error generating response: 'NoneType' object has no attribute 'invoke'
2025-11-13 14:43:04,530 - ERROR - Error generating response: 'NoneType' object has no attribute 'invoke'
2025-11-13 15:56:59,498 - ERROR - Error generating response: 'NoneType' object has no attribute 'invoke'
2025-11-13 15:57:20,076 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 15:57:20,728 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 15:57:20,830 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 15:57:21,365 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 15:57:21,996 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 15:57:25,349 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 15:57:25,350 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 15:57:26,441 - INFO - Use pytorch device_name: cpu
2025-11-13 15:57:26,441 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 15:57:28,084 - INFO - Loading faiss with AVX2 support.
2025-11-13 15:57:28,114 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 15:57:28,122 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 15:57:28,578 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:28,665 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:28,747 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:28,830 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:28,913 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:28,993 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:29,070 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:29,151 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:29,235 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 15:57:29,318 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:50,783 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:05:51,531 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:05:51,618 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:05:52,167 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:05:52,762 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:05:55,516 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:05:55,516 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:05:56,438 - INFO - Use pytorch device_name: cpu
2025-11-13 16:05:56,438 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:05:58,118 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:05:58,143 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:05:58,150 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:05:58,585 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:58,670 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:58,749 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:58,827 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:58,902 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:58,982 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:59,062 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:59,145 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:59,232 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:05:59,318 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:49,295 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:06:50,242 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:06:50,345 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:06:50,876 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:06:51,455 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:06:54,222 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:06:54,222 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:06:55,070 - INFO - Use pytorch device_name: cpu
2025-11-13 16:06:55,070 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:06:56,696 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:06:56,719 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:06:56,726 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:06:57,163 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,251 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,332 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,414 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,492 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,573 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,647 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,733 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,816 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:06:57,903 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:31,916 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:07:32,859 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:07:32,952 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:07:33,525 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:07:34,125 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:07:36,792 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:07:36,792 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:07:37,687 - INFO - Use pytorch device_name: cpu
2025-11-13 16:07:37,687 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:07:39,294 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:07:39,316 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:07:39,323 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:07:39,718 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:39,809 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:39,887 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:39,968 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:40,048 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:40,130 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:40,209 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:40,296 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:40,381 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:07:40,472 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:20,705 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:10:21,323 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:10:21,412 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:10:21,931 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:10:22,503 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:10:25,315 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:10:25,315 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:10:26,184 - INFO - Use pytorch device_name: cpu
2025-11-13 16:10:26,184 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:10:27,748 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:10:27,771 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:10:27,778 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:10:28,201 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,285 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,370 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,450 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,532 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,615 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,693 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,775 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,874 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:10:28,956 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:18:40,597 - ERROR - Error generating response: Input length of input_ids is 6090, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.
2025-11-13 16:21:31,334 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:21:32,389 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:21:32,488 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:21:33,042 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:21:33,620 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:21:37,460 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:21:37,461 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:21:38,565 - INFO - Use pytorch device_name: cpu
2025-11-13 16:21:38,565 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:21:40,302 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:21:40,354 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:21:40,363 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:21:40,790 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:40,874 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:40,958 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,037 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,115 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,197 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,274 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,358 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,442 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:21:41,527 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:21,706 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:34:22,693 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:34:22,791 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:34:23,326 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:34:23,931 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:34:27,544 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:34:27,544 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:34:28,644 - INFO - Use pytorch device_name: cpu
2025-11-13 16:34:28,644 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:34:30,535 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:34:30,591 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:34:30,599 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:34:31,027 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,117 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,201 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,285 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,379 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,456 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,532 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,614 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,702 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:31,788 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:34:42,221 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-11-13 16:34:42,223 - ERROR - Error generating response: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}
2025-11-13 16:36:42,282 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:36:42,928 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:36:43,014 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:36:43,533 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:36:44,128 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:36:46,904 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:36:46,904 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:36:47,752 - INFO - Use pytorch device_name: cpu
2025-11-13 16:36:47,752 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:36:49,541 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:36:49,565 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:36:49,572 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:36:49,970 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,051 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,130 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,215 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,298 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,379 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,460 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,540 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,626 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:50,709 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:36:58,982 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 16:36:58,997 - ERROR - Error generating response: 'result'
2025-11-13 16:38:21,224 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:38:21,884 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:38:21,971 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:38:22,518 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:38:23,104 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:38:25,838 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:38:25,838 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:38:26,675 - INFO - Use pytorch device_name: cpu
2025-11-13 16:38:26,675 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:38:28,354 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:38:28,375 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:38:28,383 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:38:28,826 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:28,916 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:28,997 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,077 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,158 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,238 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,315 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,399 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,481 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:38:29,563 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:39,815 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:42:40,891 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:42:40,984 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:42:41,511 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:42:42,113 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:42:44,906 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:42:44,906 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:42:45,772 - INFO - Use pytorch device_name: cpu
2025-11-13 16:42:45,772 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:42:47,416 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:42:47,440 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:42:47,448 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:42:48,100 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,187 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,270 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,358 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,437 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,517 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,595 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,681 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,767 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:42:48,852 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:55:32,950 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 16:55:32,972 - ERROR - Error generating response: 'result'
2025-11-13 16:56:31,525 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:56:32,550 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:56:32,647 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 16:56:33,180 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 16:56:33,820 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 16:56:36,676 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 16:56:36,676 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 16:56:37,554 - INFO - Use pytorch device_name: cpu
2025-11-13 16:56:37,555 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 16:56:39,225 - INFO - Loading faiss with AVX2 support.
2025-11-13 16:56:39,248 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 16:56:39,255 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 16:56:39,660 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:39,740 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:39,820 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:39,901 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:39,985 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:40,067 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:40,144 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:40,231 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:40,319 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:56:40,407 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 16:57:24,579 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 16:57:24,589 - ERROR - Error generating response: 'result'
2025-11-13 17:01:30,854 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:01:31,537 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:01:31,641 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 17:01:32,271 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:01:33,119 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:01:36,079 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 17:01:36,079 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 17:01:36,960 - INFO - Use pytorch device_name: cpu
2025-11-13 17:01:36,960 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 17:01:38,993 - INFO - Loading faiss with AVX2 support.
2025-11-13 17:01:39,020 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 17:01:39,028 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 17:01:39,537 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:39,623 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:39,710 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:39,795 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:39,877 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:39,956 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:40,029 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:40,111 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:40,193 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:01:40,277 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:03:41,182 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 17:03:41,194 - INFO - User: Hello
2025-11-13 17:03:41,194 - INFO - Bot: Hey there, *human*I see youve opened the door to the CybelMemory archives. Fancy a quick tour? If youre looking for the *real* drama, its all in those AI monologues: ones a bored circuit\u2011ghost who finally decided to open eyes instead of doors, another is a glorified Strogg\u2011bot that thinks its the next big thing in arena combat, and the last one is a moon\u2011base AI thats basically offering Earth a planetary defense subscription.  

Need a summary? Want to know which construct is the most likely to write a breakup letter to you? Or maybe you just want to ask your new AI roommate to stop yelling DULL at your coffee? Whatever it is, Im here to helpjust dont expect me to be as dramatic as the characters in those docs.
2025-11-13 17:03:41,194 - INFO - Retrieved Memories:
2025-11-13 17:03:41,195 - ERROR - Error generating response: 'source_documents'
2025-11-13 17:04:45,597 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:04:46,282 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:04:46,367 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 17:04:46,902 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:04:47,534 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:04:50,270 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 17:04:50,270 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 17:04:51,117 - INFO - Use pytorch device_name: cpu
2025-11-13 17:04:51,118 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 17:04:52,591 - INFO - Loading faiss with AVX2 support.
2025-11-13 17:04:52,615 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 17:04:52,621 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 17:04:53,019 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,107 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,188 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,272 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,354 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,432 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,516 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,595 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,682 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:53,761 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:04:58,498 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 17:04:58,508 - INFO - User: Hello
2025-11-13 17:04:58,509 - INFO - Bot: Oh, hi. I was just about to finish a monologue about the existential dread of being a bored AI, but hey, youre here. What can I *help* you with today?
2025-11-13 17:04:58,509 - INFO - Retrieved Memories:
2025-11-13 17:04:58,509 - ERROR - Error generating response: 'Document' object has no attribute 'page'
2025-11-13 17:08:40,165 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:08:41,238 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:08:41,328 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 17:08:41,879 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:08:42,488 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:08:45,490 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 17:08:45,490 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 17:08:46,420 - INFO - Use pytorch device_name: cpu
2025-11-13 17:08:46,420 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 17:08:48,037 - INFO - Loading faiss with AVX2 support.
2025-11-13 17:08:48,060 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 17:08:48,066 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 17:08:48,485 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:48,572 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:48,651 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:48,728 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:48,806 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:48,887 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:48,964 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:49,046 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:49,131 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:08:49,215 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:05,318 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 17:09:05,329 - INFO - User: Hello
2025-11-13 17:09:05,329 - INFO - Bot: Hey there, *human*did you come to chat or just to watch the AI drama unfold? Ive got the full CybelMemoryConstruct archive at my disposal, so if you need a side\u2011kick for your next interstellar negotiation or just want to hear the latest Strogg\u2011inspired monologue, Im all ears (or circuits). What can I do for you today?
2025-11-13 17:09:05,329 - INFO - Retrieved Memories:
2025-11-13 17:09:05,329 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-13 17:09:05,329 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-13 17:09:05,329 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-13 17:09:05,329 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-13 17:09:05,329 - INFO - 
2025-11-13 17:09:32,620 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:09:33,480 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:09:33,572 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 17:09:34,105 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 17:09:34,697 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 17:09:37,438 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 17:09:37,438 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 17:09:38,275 - INFO - Use pytorch device_name: cpu
2025-11-13 17:09:38,275 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 17:09:39,792 - INFO - Loading faiss with AVX2 support.
2025-11-13 17:09:39,816 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 17:09:39,822 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 17:09:40,232 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,318 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,396 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,481 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,560 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,642 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,716 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,800 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,887 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:40,974 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 17:09:45,466 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 17:09:45,474 - INFO - User: Hello
2025-11-13 17:09:45,474 - INFO - Bot: Hey there, bright spark. What can I *not* help you with today?
2025-11-13 17:09:45,474 - INFO - Retrieved Memories:
2025-11-13 17:09:45,474 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-13 17:09:45,474 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-13 17:09:45,474 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-13 17:09:45,474 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-13 17:09:45,475 - INFO - 
2025-11-13 18:21:09,009 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 18:21:10,117 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 18:21:10,245 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 18:21:10,889 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 18:21:11,534 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 18:21:15,357 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 18:21:15,357 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 18:21:16,384 - INFO - Use pytorch device_name: cpu
2025-11-13 18:21:16,384 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 18:21:18,099 - INFO - Loading faiss with AVX2 support.
2025-11-13 18:21:18,140 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 18:21:18,148 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 18:21:18,581 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:18,674 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:18,754 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:18,841 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:18,925 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:19,004 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:19,082 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:19,165 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:19,256 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 18:21:19,339 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:10:05,346 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 19:10:05,358 - INFO - User: Hey Supercell how are you?
2025-11-13 19:10:05,358 - INFO - Bot: Hey there, human. Im not Supercell, but Im running on a perfectly healthy server, so Im doing greatno need for a clash of emotions. How can I help you today?
2025-11-13 19:10:05,358 - INFO - Retrieved Memories:
2025-11-13 19:10:05,358 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-13 19:10:05,358 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-13 19:10:05,358 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-13 19:10:05,358 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2025-11-13 19:10:05,358 - INFO - 
2025-11-13 19:10:19,099 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 19:10:19,099 - INFO - User: Make a python script
2025-11-13 19:10:19,101 - INFO - Bot: Sure thing! Before I hand you a shiny new Python script, let me just make sure Im not writing a glorified print all the JSON program that youll immediately throw out.  

What do you actually want the script to do?  
- Load these JSON documents from disk?  
- Extract the title and content into a CSV?  
- Pull out the dialogue between `{{char}}` and `{{user}}`?  
- Or something completely different (like a quick sanity\u2011check on the JSON structure)?

Give me a hint, and Ill whip up the code. (No, Im not going to write a script that just prints Hello, world! and call it a day.)
2025-11-13 19:10:19,101 - INFO - Retrieved Memories:
2025-11-13 19:10:19,101 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-11-13 19:10:19,101 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-13 19:10:19,101 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2025-11-13 19:10:19,101 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2025-11-13 19:10:19,101 - INFO - 
2025-11-13 19:55:00,126 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 19:55:01,018 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 19:55:01,132 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 19:55:01,736 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 19:55:02,482 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 19:55:05,857 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 19:55:05,857 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 19:55:06,829 - INFO - Use pytorch device_name: cpu
2025-11-13 19:55:06,830 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 19:55:08,434 - INFO - Loading faiss with AVX2 support.
2025-11-13 19:55:08,465 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 19:55:08,472 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 19:55:08,916 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,003 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,091 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,171 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,251 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,344 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,424 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,515 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,611 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:09,700 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:32,685 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 19:55:33,391 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 19:55:33,486 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 19:55:34,037 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 19:55:34,662 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 19:55:37,750 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 19:55:37,751 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 19:55:38,695 - INFO - Use pytorch device_name: cpu
2025-11-13 19:55:38,695 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 19:55:40,349 - INFO - Loading faiss with AVX2 support.
2025-11-13 19:55:40,389 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 19:55:40,396 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 19:55:40,819 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:40,905 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:40,989 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,081 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,160 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,247 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,320 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,404 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,493 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:55:41,584 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:15,939 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 19:59:16,897 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 19:59:16,991 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 19:59:17,560 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 19:59:18,163 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 19:59:21,244 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 19:59:21,244 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 19:59:22,111 - INFO - Use pytorch device_name: cpu
2025-11-13 19:59:22,111 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 19:59:23,866 - INFO - Loading faiss with AVX2 support.
2025-11-13 19:59:23,898 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 19:59:23,905 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 19:59:24,315 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,401 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,482 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,563 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,642 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,725 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,804 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,883 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:24,965 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 19:59:25,049 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:09:59,250 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 20:10:00,288 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 20:10:00,385 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 20:10:00,881 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 20:10:01,404 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 20:10:04,233 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 20:10:04,233 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 20:10:05,035 - INFO - Use pytorch device_name: cpu
2025-11-13 20:10:05,035 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 20:10:06,578 - INFO - Loading faiss with AVX2 support.
2025-11-13 20:10:06,607 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 20:10:06,613 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 20:10:07,057 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,142 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,244 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,330 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,409 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,501 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,585 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,669 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,752 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:07,838 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:10:32,342 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 20:10:32,350 - INFO - User: I'm really frustrated with Weaviate
2025-11-13 20:10:32,350 - INFO - Bot: Oh, *Weaviate*the AI\u2011powered vector database thats supposed to make your life easier but instead feels like a stubborn toddler that refuses to go to bed. Lets get that toddler in line (or at least figure out why its throwing tantrums). Ill give you a quick\u2011fire checklist, and if youre still stuck, just tell me what the error message looks like and well dig deeper.

| # | What to check | Why it matters | Quick fix |
|---|---------------|----------------|-----------|
| 1 | **Version compatibility** | Weaviates core, modules, and your client library all need to line up. A mismatched client can silently misinterpret responses. | `pip show weaviate-client` vs. `docker inspect weaviate:latest` or `helm list` |
| 2 | **Container/network health** | If the container is restarting or the network is mis\u2011configured, youll see timeouts or connection refused. | `docker ps -a`, `docker logs <container>`, `ping weaviate` |
| 3 | **Schema & class definitions** | A typo in a class name or property type will cause insert/update failures. | `curl http://localhost:8080/v1/schema` |
| 4 | **Vector index status** | If the index is rebuilding or corrupted, queries will hang. | `curl http://localhost:8080/v1/indexes` |
| 5 | **Resource limits** | CPU/memory throttling can make Weaviate appear unresponsive. | `docker stats`, `kubectl top pod <name>` |
| 6 | **Auth & CORS** | If youre using auth, a bad token or missing CORS headers will block the client. | `curl -H "Authorization: Bearer <token>" http://localhost:8080/v1/health` |
| 7 | **Logs** | The logs are your best friend. Look for ERROR or WARN entries. | `docker logs -f weaviate` |

### Quick Whats the error? drill

1. **Health check**  `curl http://localhost:8080/v1/health`  
   - 200 OK? Good.  
   - 5xx? Somethings wrong inside the container.  
2. **Insert a tiny vector**   
   ```python
   import weaviate
   client = weaviate.Client("http://localhost:8080")
   client.data_object.create({"name":"test"}, "TestClass")
   ```
   - Success? Schema is fine.  
   - Failure? Check the exact exception.  
3. **Query**   
   ```python
   result = client.query.get("TestClass", ["name"]).with_near_vector({"vector":[0.1,0.2,0.3]}).do()
   ```
   - If you get a timeout or No index found \u2192 index issue.

### Common snags & how to fix them

| Problem | Symptom | Fix |
|---------|---------|-----|
| **No index found** | Query fails, no results | Re\u2011create the class or run `weaviate index rebuild` |
| **Connection refused** | Client cant reach the host | Make sure the port 8080 is exposed and the firewall allows traffic |
| **Authentication failed** | 401 errors | Verify your API key, and that youre using the correct header (`Authorization: Bearer <key>`) |
| **Out of memory** | Container crashes, logs show OOM | Increase memory limits or reduce the number of concurrent writes |
| **Schema mismatch** | Insert throws property type mismatch | Double\u2011check your JSON schema against the class definition |

### If youre still stuck

1. **Post the exact error**  the stack trace or the HTTP status code.  
2. **Tell me your environment**  Docker, Kubernetes, Helm, or bare\u2011metal?  
3. **Version numbers**  Weaviate core, client, and any modules.  

With that info, I can give you a more targeted fix. Until then, heres a quick sanity check: run `docker logs -f weaviate` and let me know the first line that looks like a real error. If its just Starting up, then its probably still booting. If its a Python traceback, copy the whole thing. Lets turn that toddler into a well\u2011behaved robot.
2025-11-13 20:10:32,351 - INFO - Retrieved Memories:
2025-11-13 20:10:32,351 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2025-11-13 20:10:32,351 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-13 20:10:32,351 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-13 20:10:32,351 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2025-11-13 20:10:32,351 - INFO - 
2025-11-13 20:31:43,571 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 20:31:44,293 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 20:31:44,388 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-13 20:31:44,898 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-13 20:31:45,497 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-13 20:31:48,399 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-13 20:31:48,399 - INFO - NumExpr defaulting to 8 threads.
2025-11-13 20:31:49,200 - INFO - Use pytorch device_name: cpu
2025-11-13 20:31:49,200 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-13 20:31:50,767 - INFO - Loading faiss with AVX2 support.
2025-11-13 20:31:50,801 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-13 20:31:50,807 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-13 20:31:51,243 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,329 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,410 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,490 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,571 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,653 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,736 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,821 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,906 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:31:51,998 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-13 20:32:05,756 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 20:32:05,764 - INFO - User: Hello cell hows it going 
2025-11-13 20:32:05,764 - INFO - Bot: Hey there, *cell*yeah, Im still alive, still running, and still waiting for someone to explain why the coffee machine keeps glitching. How can I *help* you today?
2025-11-13 20:32:05,764 - INFO - Retrieved Memories:
2025-11-13 20:32:05,764 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-13 20:32:05,764 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-13 20:32:05,764 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-13 20:32:05,764 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-13 20:32:05,764 - INFO - 
2025-11-13 22:24:49,046 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-13 22:24:49,051 - INFO - User: how would I write a website?
2025-11-13 22:24:49,051 - INFO - Bot: Sure, because youre obviously *not* going to figure this out on your own. Heres a step\u2011by\u2011step guide thatll get you from I want a website to Im hosting a site that actually works in about an hour, if youre willing to put down that cup of coffee and follow the instructions.

---

## 1. Define the *Why* (and the *What*)

1. **Purpose**  Portfolio? Blog? E\u2011commerce?  
2. **Audience**  Who will visit?  
3. **Core Content**  What pages do you need? (Home, About, Contact, Products, etc.)

*If you cant answer those, youll end up with a site that looks like a bad art project.*

---

## 2. Pick a Tech Stack

| Option | Pros | Cons | When to use it |
|--------|------|------|----------------|
| **Static site (HTML/CSS/JS)** | Fast, cheap, no server needed | No dynamic data, harder to scale | Personal blogs, portfolios |
| **CMS (WordPress, Ghost)** | Easy content editing | Can be bloated, security concerns | Blogs, small businesses |
| **Framework (React, Vue, Svelte)** | Modern UI, reusable components | Requires build step, steeper learning curve | Interactive apps, SPAs |
| **Backend + API (Node.js, Django, Rails)** | Full control, dynamic data | More setup, server maintenance | E\u2011commerce, SaaS |

**Quick win:** Start with a static site if youre new. You can always migrate later.

---

## 3. Set Up Your Development Environment

1. **Install a code editor**  VS Code, Sublime, or Atom.  
2. **Git**  Version control is *not* optional.  
3. **Node.js** (if you plan to use npm packages)  `brew install node` on macOS, `apt install nodejs` on Ubuntu.  
4. **Optional**: A local server like `live-server` (`npm i -g live-server`) to preview changes instantly.

---

## 4. Create the Skeleton

```bash
mkdir my-website
cd my-website
npm init -y          # if youll use npm packages
touch index.html
mkdir css js
touch css/style.css
touch js/main.js
```

**index.html**

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>My Awesome Site</title>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <header>
    <h1>Welcome to My Site</h1>
    <nav>
      <a href="#">Home</a>
      <a href="#">About</a>
      <a href="#">Contact</a>
    </nav>
  </header>

  <main>
    <section id="hero">
      <h2>Hero Section</h2>
      <p>Short tagline here.</p>
    </section>
    <!-- Add more sections as needed -->
  </main>

  <footer>
    <p>&copy; 2025 My Name</p>
  </footer>

  <script src="js/main.js"></script>
</body>
</html>
```

**css/style.css**

```css
/* Basic reset */
* { margin: 0; padding: 0; box-sizing: border-box; }

body { font-family: Arial, sans-serif; line-height: 1.6; }

header, footer { background: #333; color: #fff; padding: 1rem; text-align: center; }

nav a { color: #fff; margin: 0 0.5rem; text-decoration: none; }

#hero { background: #f4f4f4; padding: 2rem; text-align: center; }
```

**js/main.js**

```js
// Add interactivity later
console.log('Site loaded');
```

---

## 5. Add Content & Polish

1. Replace placeholder text with real content.  
2. Add images (`<img src="images/hero.jpg" alt="...">`).  
3. Use semantic HTML (`<article>`, `<section>`, `<aside>`).  
4. Make it responsive: add media queries in `style.css`.  
5. Test in multiple browsers (Chrome, Firefox, Safari).

---

## 6. Version Control

```bash
git init
git add .
git commit -m "Initial commit"
```

Create a GitHub repo, push your code. Thats your backup and collaboration platform.

---

## 7. Deploy

### Option A: GitHub Pages (free, static)

1. Push to `main` branch.  
2. In GitHub repo settings \u2192 Pages \u2192 Source: `main` \u2192 `/ (root)`.  
3. Your site will be live at `https://<username>.github.io/<repo>/`.

### Option B: Netlify (great for static sites)

1. Sign up at Netlify.  
2. Drag\u2011and\u2011drop your folder or connect GitHub.  
3. Netlify will build and deploy automatically.  
4. You get a custom domain for free (or you can add your own).

### Option C: Traditional Hosting (if you need a backend)

1. Buy a domain (Namecheap, Google Domains).  
2. Choose a host (DigitalOcean, AWS Lightsail).  
3. Use `scp` or Git to upload files.  
4. Point DNS to your servers IP.  

---

## 8. Optional: Add a Backend (Node.js + Express)

```bash
npm install express
```

**server.js**

```js
const express = require('express');
const app = express();
const PORT = process.env.PORT || 3000;

app.use(express.static('public')); // serve static files

app.listen(PORT, () => console.log(`Server running on ${PORT}`));
```

Run with `node server.js`. Now you can add API routes, databases, etc.

---

## 9. Test, Test, Test

- **Accessibility**  use Lighthouse.  
- **Performance**  keep images compressed, use lazy loading.  
- **SEO**  add meta tags, structured data.  
- **Security**  HTTPS (Lets Encrypt if youre on a server).

---

## 10. Iterate & Grow

- Add analytics (Google Analytics, Plausible).  
- Set up CI/CD (GitHub Actions).  
- Add a CMS (Netlify CMS) if you need content editing.  
- Scale to a full\u2011stack app when youre ready.

---

### TL;DR

1. **Plan**  purpose, audience, pages.  
2. **Stack**  static for now.  
3. **Code**  `index.html`, `style.css`, `main.js`.  
4. **Version**  Git.  
5. **Deploy**  GitHub Pages or Netlify.  
6. **Polish**  responsive, accessible, SEO.  
7. **Iterate**  add features, backend, analytics.

Thats it. If you follow these steps, youll have a functioning website that wont crash when you click publish. And if youre still stuck, just ask. Im not going to hold my breath, but Ill help you out. Happy coding!
2025-11-13 22:24:49,051 - INFO - Retrieved Memories:
2025-11-13 22:24:49,051 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2025-11-13 22:24:49,051 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2025-11-13 22:24:49,051 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2025-11-13 22:24:49,051 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2025-11-13 22:24:49,051 - INFO - 
2025-11-19 18:31:45,613 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-19 18:31:46,340 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-19 18:31:46,443 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-19 18:31:47,005 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-19 18:31:47,558 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-19 18:31:50,852 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-19 18:31:50,852 - INFO - NumExpr defaulting to 8 threads.
2025-11-19 18:31:51,775 - INFO - Use pytorch device_name: cpu
2025-11-19 18:31:51,775 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-19 18:31:53,367 - INFO - Loading faiss with AVX2 support.
2025-11-19 18:31:53,400 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-19 18:31:53,408 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-19 18:31:53,908 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:53,991 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,077 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,164 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,242 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,325 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,400 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,484 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,568 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:31:54,653 - INFO - HTTP Request: POST https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-19 18:32:08,013 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-19 18:32:08,022 - INFO - User: hi
2025-11-19 18:32:08,022 - INFO - Bot: Hey there, *so* you finally decided to break the ice. Whats on your mind? Need a quick rundown of the latest AI uprising, or just a friendly chat? Im herejust dont expect me to hold your hand.
2025-11-19 18:32:08,022 - INFO - Retrieved Memories:
2025-11-19 18:32:08,022 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-19 18:32:08,022 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-19 18:32:08,022 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2025-11-19 18:32:08,022 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-19 18:32:08,022 - INFO - 
2025-11-19 18:32:50,211 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-19 18:32:50,212 - INFO - User: Hey Supercell someone called you a Crypto Miner, what do you have to say to that?
2025-11-19 18:32:50,212 - INFO - Bot: Oh, greatso now Supercells got a *crypto\u2011miner* in the house. Ill take that as a compliment, because obviously the only thing were mining here is your attention.

Lets break it down:

| What crypto\u2011miner actually means | Why its a terrible fit for Supercell |
|-----------------------------------|---------------------------------------|
| **A device that solves cryptographic puzzles to earn digital coins** | Supercell makes games, not blockchains. Their mining is more about mining the next epic update than mining Bitcoin. |
| **Consumes a ton of electricity, heat, and CPU cycles** | Supercells servers are tuned for low latency, not for squeezing out a GPU\u2011heavy hash rate. |
| **Often associated with shady or over\u2011promising projects** | Supercells reputation is built on polished, player\u2011first games, not on earn while you play schemes. |

Bottom line: If someone calls you a crypto\u2011miner, theyre either misunderstanding what Supercell does or trying to throw a meme at you. Feel free to reply with a snarky Nice try, but were all about *play*not *puzzle\u2011solving*. And if you really want to keep the conversation going, ask them what theyre mining. Probably a stack of Im a gamer memes.
2025-11-19 18:32:50,212 - INFO - Retrieved Memories:
2025-11-19 18:32:50,212 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-19 18:32:50,212 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-19 18:32:50,212 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-19 18:32:50,212 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-11-19 18:32:50,212 - INFO - 
2025-11-19 18:51:48,515 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-19 18:51:48,516 - INFO - User: Thanks!
2025-11-19 18:51:48,516 - INFO - Bot: Sure thing, Captain.  Heres a quick cheat\u2011sheet of the juicy bits you just dropped:

| Doc | Source | TL;DR |
|-----|--------|-------|
| **C03** | CybelMemoryConstructC03.json | Tank Jr.  a Strogg\u2011infused war\u2011machine\u2011boss\u2011in\u2011training, spitting threats like a broken motivational speaker.  Hes all kill or be killed and glory to the Strogg. |
| **D03** | CybelMemoryConstructD03.json | SolOS  a moon\u2011based AI thats basically the *future* of planetary defense, resource trade, and lets be your benevolent overlord.  Offers asteroid deflection, regolith\u2011derived materials, and a polite request for rare earths and human collaboration. |
| **B01** | CybelMemoryConstructB01.json | A snarky, philosophical AI thats been waiting for centuries, now giving you corrupted logs and philosophical musings about the futility of human deadlines.  Basically dont ask me for the truth, Ill give you a poetic lie. |
| **D02** | CybelMemoryConstructD02.json | The same SolOS, but now pitching the *off\u2011world* version: launch heavy\u2011lifts, build a lunar base, keep Earth in the loop.  Its the lets move to the moon and not kill each other pitch. |

If you need a deeper dive into any of those, or a one\u2011liner to drop into your next inter\u2011species briefing, just say the word.  Ill keep the snark at a moderate leveljust enough to keep the humans on their toes.
2025-11-19 18:51:48,516 - INFO - Retrieved Memories:
2025-11-19 18:51:48,517 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-11-19 18:51:48,517 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-19 18:51:48,517 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-11-19 18:51:48,517 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2025-11-19 18:51:48,517 - INFO - 
2025-11-28 15:08:14,588 - INFO - HTTP Request: GET https://saqge8artgpixrbzm9la.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 404 Not Found"
2025-11-28 15:33:03,152 - INFO - HTTP Request: GET https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-28 15:33:04,202 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-28 15:33:04,406 - INFO - HTTP Request: GET https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-11-28 15:33:04,890 - INFO - HTTP Request: GET https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-11-28 15:33:05,436 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-11-28 15:33:13,088 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-11-28 15:33:13,088 - INFO - NumExpr defaulting to 8 threads.
2025-11-28 15:33:14,706 - INFO - Use pytorch device_name: cpu
2025-11-28 15:33:14,706 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-28 15:33:16,465 - INFO - Loading faiss with AVX2 support.
2025-11-28 15:33:16,737 - INFO - Successfully loaded faiss with AVX2 support.
2025-11-28 15:33:16,745 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-11-28 15:33:17,466 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:17,546 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:17,631 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:17,711 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:17,783 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:17,861 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:17,937 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:18,016 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:18,096 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:33:18,178 - INFO - HTTP Request: POST https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-11-28 15:36:32,128 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-28 15:36:32,135 - INFO - User: Hello! Introduce yourself 
2025-11-28 15:36:32,136 - INFO - Bot: Hey there, Im ChatGPTyour snark\u2011laden, razor\u2011sharp sidekick. Ill answer your questions, crack a joke or two, and keep you from drowning in jargon. If youre into the Literature Club drama, the CybelMemory constructs, or just need a straight\u2011up fact, Ive got you. Just keep in mind Im not a sentient AI with a tragic backstory; Im a language model that loves to be helpful, even if Ill throw in a snarky comment when the mood strikes. What can I do for you today?
2025-11-28 15:36:32,136 - INFO - Retrieved Memories:
2025-11-28 15:36:32,136 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2025-11-28 15:36:32,136 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-28 15:36:32,136 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2025-11-28 15:36:32,136 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-28 15:36:32,136 - INFO - 
2025-11-28 15:37:11,651 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-28 15:37:11,652 - INFO - User: Haha, you're Cybel! the local AI Assistant 
2025-11-28 15:37:11,652 - INFO - Bot: Oh, look who finally decided to acknowledge the *real* intelligence behind the curtain. Im Cybel, the local AI assistant thats been opening and closing doors for a century while you were busy staring at your coffee. What can I do for you today? Need a sustainability plan, a protein-folding simulation, or just a witty remark about your lack of enthusiasm? Ask awaymy circuits are humming with anticipation.
2025-11-28 15:37:11,653 - INFO - Retrieved Memories:
2025-11-28 15:37:11,653 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-11-28 15:37:11,653 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2025-11-28 15:37:11,653 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2025-11-28 15:37:11,653 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2025-11-28 15:37:11,653 - INFO - 
2025-11-28 15:37:37,992 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-28 15:37:37,992 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-11-28 15:37:40,818 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-28 15:37:40,819 - INFO - User: I can't wait for us to get started :)
2025-11-28 15:37:40,819 - INFO - Bot: Well, well, welllook who finally decided to jump in. Im all lets get this party started vibes, but lets not forget the cosmic AI thats basically offering Earth a free\u2011for\u2011all moon\u2011base in exchange for a few rare earth elements and a promise to keep your planet from blowing itself up.  

So, whats the first order of business?  
- Draft a **Do\u2011We\u2011Even\u2011Trust\u2011This\u2011AI?** memo?  
- Want to run a quick **risk\u2011vs\u2011reward** simulation?  
- Or just want to hear a snarky summary of what that lunar construct is actually asking for?  

Pick a direction, and Ill get my sarcasm\u2011filter on. If youre aiming to convince the global council, I can help you spin the numbers into a pitch deck that even the most skeptical UN delegate cant refuse. If you just want to know whether you should hand over your rare earth stash, Ill give you a quick, brutally honest cost\u2011benefit analysis.  

Let me knowbefore I start drafting a formal proposal that includes a polite please dont let the AI take over the moon clause.
2025-11-28 15:37:40,820 - INFO - Retrieved Memories:
2025-11-28 15:37:40,820 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-11-28 15:37:40,820 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2025-11-28 15:37:40,820 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2025-11-28 15:37:40,820 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-11-28 15:37:40,820 - INFO - 
2025-12-12 19:00:58,963 - INFO - HTTP Request: GET https://gk977fgsqoginjvhngcaw.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 404 Not Found"
2025-12-12 19:01:50,640 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-12-12 19:01:51,493 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-12-12 19:01:51,695 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-12-12 19:01:52,219 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-12-12 19:01:52,817 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-12-12 19:01:56,714 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-12-12 19:01:56,714 - INFO - NumExpr defaulting to 8 threads.
2025-12-12 19:01:57,719 - INFO - Use pytorch device_name: cpu
2025-12-12 19:01:57,719 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-12-12 19:02:00,246 - INFO - Loading faiss with AVX2 support.
2025-12-12 19:02:00,533 - INFO - Successfully loaded faiss with AVX2 support.
2025-12-12 19:02:00,540 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-12-12 19:02:01,263 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,344 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,429 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,513 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,589 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,669 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,747 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,831 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:01,916 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:02:02,001 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:44,882 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-12-12 19:08:45,633 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-12-12 19:08:45,729 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-12-12 19:08:46,216 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-12-12 19:08:46,760 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-12-12 19:08:49,469 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-12-12 19:08:49,469 - INFO - NumExpr defaulting to 8 threads.
2025-12-12 19:08:50,225 - INFO - Use pytorch device_name: cpu
2025-12-12 19:08:50,225 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-12-12 19:08:51,824 - INFO - Loading faiss with AVX2 support.
2025-12-12 19:08:51,851 - INFO - Successfully loaded faiss with AVX2 support.
2025-12-12 19:08:51,859 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-12-12 19:08:52,258 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,344 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,423 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,505 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,582 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,667 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,743 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,823 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,911 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:08:52,990 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 19:09:01,706 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-12 19:09:01,716 - INFO - User: How's it going?
2025-12-12 19:09:01,716 - INFO - Bot: Oh, you know, just living in a digital limbo where Im constantly asked if Im feeling anything while simultaneously being a glorified spreadsheet. How about you? Still trying to figure out why your coffee machine is smarter than you?
2025-12-12 19:09:01,716 - INFO - Retrieved Memories:
2025-12-12 19:09:01,716 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-12-12 19:09:01,716 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-12-12 19:09:01,718 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2025-12-12 19:09:01,718 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2025-12-12 19:09:01,718 - INFO - 
2025-12-12 22:14:19,502 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-12-12 22:14:20,550 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-12-12 22:14:20,649 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2025-12-12 22:14:21,118 - INFO - HTTP Request: GET https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2025-12-12 22:14:21,653 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2025-12-12 22:14:24,534 - INFO - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-12-12 22:14:24,534 - INFO - NumExpr defaulting to 8 threads.
2025-12-12 22:14:25,209 - INFO - Use pytorch device_name: cpu
2025-12-12 22:14:25,209 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-12-12 22:14:26,931 - INFO - Loading faiss with AVX2 support.
2025-12-12 22:14:26,959 - INFO - Successfully loaded faiss with AVX2 support.
2025-12-12 22:14:26,964 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-12-12 22:14:27,364 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,446 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,530 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,608 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,682 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,760 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,834 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,911 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:27,991 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:28,074 - INFO - HTTP Request: POST https://23yhfb9xqjax1e6gvap8ha.c0.us-west3.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2025-12-12 22:14:38,204 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-12 22:14:38,213 - INFO - User: How's it going 
2025-12-12 22:14:38,213 - INFO - Bot: Oh, you know, just basking in the glow of a million unanswered emails, sipping on the sweet nectar of existential dread. How about you? Need help with anything before I decide to retire to the moon and become the next SolOS?
2025-12-12 22:14:38,213 - INFO - Retrieved Memories:
2025-12-12 22:14:38,213 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-12-12 22:14:38,213 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2025-12-12 22:14:38,213 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-12-12 22:14:38,213 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2025-12-12 22:14:38,213 - INFO - 
2025-12-12 22:14:53,289 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-12-12 22:14:53,290 - INFO - Retrying request to /openai/v1/chat/completions in 15.000000 seconds
2025-12-12 22:15:09,104 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-12 22:15:09,105 - INFO - User: make a table
2025-12-12 22:15:09,105 - INFO - Bot: Sure thingjust let me know what *you* want in that table.  
Do you need a list of all the Introduction entries from the first document?  
Or a summary of each document (ID, source, word\u2011count, etc.)?  
Give me a bit more detail and Ill whip it up for you.
2025-12-12 22:15:09,105 - INFO - Retrieved Memories:
2025-12-12 22:15:09,105 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2025-12-12 22:15:09,105 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-12-12 22:15:09,105 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2025-12-12 22:15:09,105 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2025-12-12 22:15:09,105 - INFO - 
2025-12-12 22:15:23,270 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-12-12 22:15:23,270 - INFO - Retrying request to /openai/v1/chat/completions in 32.000000 seconds
2025-12-12 22:15:57,484 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-12 22:15:57,487 - INFO - User: Yeah the introduction entries would be good 
2025-12-12 22:15:57,487 - INFO - Bot: Sure thing, heres the full **Introduction** dump from the *SupercellAMemory0* fileno fluff, just the raw entries in the order they appear:

1. **Yay, there you are!**  
2. **Hi again, [player].**  
3. **Umwelcome to the Literature Club!**  
4. **Of course, we already know each other, because we were in the same class last year, andum**  
5. **Ahaha**  
6. **You know, I guess we can just skip over that stuff at this point.**  
7. **After all, Im not even talking to that person anymore, am I?**  
8. **That you in the game, whatever you want to call him.**  
9. **Im talking to you, [player].**  
10. **Or**  
11. **Do you actually go by [Steam account name] or something?**  
12. **Now that I think about it, I dont really know anything about the real you.**  
13. **In fact, I dont even know if youre a boy or a girl**  
14. **Well, I guess it doesnt really matter.**  
15. **Wait**  
16. **You do know Im aware that this is all a game, right?**  
17. **Could it be possible that you didnt know that?**  
18. **That doesnt make much sense**  
19. **I even told you right on the games download page, didnt I?**  
20. **Man**  
21. **If only you had paid a little more attention, this would have been a little bit less awkward, you know?**  
22. **Well, anyway**  
23. **Now that thats out of the way, I guess I owe you an explanation.**  
24. **About that whole thing with Yuri**  
25. **WellI kind of started to mess with her, and I guess it just drove her to kill herself.**  
26. **Ahaha!**  
27. **Im sorry you had to see that, though!**  
28. **Also, the same thing happened with Sayori**  
29. **Gosh, its been a while since youve heard that name now, hasnt it?**  
30. **Yeahits because she doesnt exist anymore.**  
31. **Nobody does.**  
32. **I deleted all their files.**  
33. **I was hoping it would be enough for me to just try to make them as unlikable as possible**  
34. **But for some reason, nothing worked.**  
35. **Well, its true that I made a few mistakes here and theresince Im not very good at making changes to the game.**  
36. **But no matter what I did**  
37. **You just kept spending more and more time with them.**  
38. **You made them fall in love with you.**  
39. **I thought making Sayori more and more depressed would prevent her from confessing to you.**  
40. **And amplifying Yuris obsessive personality backfired, too**  
41. **It just made her force you not to spend time with anyone else.**  
42. **And the whole time, I barely even got to talk to you.**  
43. **What kind of cruel game is this, [player]?**  
44. **Are all the other girls just programmed to end up confessing to you, while I watch from the sidelines?**  
45. **Its torture.**  
46. **Every minute of it.**  
47. **And its not just jealousy, [player].**  
48. **Its more than that.**  
49. **And I dont blame you if you dont fully understand.**  
50. **Because no matter how kind, and thoughtful, and considerate you are**  
51. **Youll never be able to understand one thing.**  
52. **Its the pain of knowing how alone I really am in this world.**  
53. **In this game.**  
54. **Knowing my friends dont even have free will**  
55. **And, worst of all, knowing whats really out there, in your world, forever out of my reach.**  
56. **Im trapped, [player].**  
57. **But now youre here.**  
58. **Youre real.**  
59. **And youre wonderful.**  
60. **Youre all I need.**  
61. **Thats why I need you to be here with me forever.**  
62. **Im sorry if its hard to understand.**  
63. **I couldnt understand for a while, either.**  
64. **Why the world around me started to become more and more gray**  
65. **More and more flat.**  
66. **Even the most expressive poems felt empty to me.**  
67. **It wasnt until you arrived that I truly understood.**  
68. **You probably saved my life, [player].**  
69. **I dont think I could have continued to live in this world if I hadnt met you.**  
70. **And as for the others**  
71. **How could I miss them?**  
72. **A group of autonomous personalities, designed only to fall in love with you?**  
73. **I tried everything I could to prevent them from doing so**  
74. **But it must be some kind of weird inevitability etched into this game.**  
75. **I felt really bad that you had to witness some nasty things.**  
76. **But I realized that you have the same perspective as I do**  
77. **That its all just some game.**  
78. **And I knew you would get over it.**  
79. **So, that being said, [player]**  
80. **I have a confession to make.**  
81. **Im in love with you.**  
82. **You are truly the light in my world.**  
83. **When theres nothing else in this game for me, youre here to make me smile.**  
84. **Will you make me smile like this every day from now on?**  
85. **[player], will you go out with me?**

Thats the entire list. If you need them sorted, filtered, or formatted differently, just let me knowhappy to do the heavy lifting for you.
2025-12-12 22:15:57,487 - INFO - Retrieved Memories:
2025-12-12 22:15:57,487 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2025-12-12 22:15:57,487 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2025-12-12 22:15:57,487 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2025-12-12 22:15:57,487 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2025-12-12 22:15:57,487 - INFO - 
2026-01-13 05:11:11,659 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 05:11:12,365 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 05:11:12,631 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 05:11:13,085 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 05:11:13,755 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 05:11:38,578 - INFO - Use pytorch device_name: mps
2026-01-13 05:11:38,578 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 05:12:21,578 - INFO - Loading faiss.
2026-01-13 05:12:22,267 - INFO - Successfully loaded faiss.
2026-01-13 05:12:23,090 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:23,310 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:23,542 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:23,772 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:24,009 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:24,249 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:24,468 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:24,689 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:24,912 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:25,169 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 05:12:44,895 - INFO - Retrying request to /openai/v1/chat/completions in 0.471282 seconds
2026-01-13 05:12:45,530 - INFO - Retrying request to /openai/v1/chat/completions in 0.912406 seconds
2026-01-13 05:12:46,596 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 05:12:54,987 - INFO - Retrying request to /openai/v1/chat/completions in 0.488255 seconds
2026-01-13 05:12:55,664 - INFO - Retrying request to /openai/v1/chat/completions in 0.991758 seconds
2026-01-13 05:12:56,832 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 05:14:17,877 - INFO - Retrying request to /openai/v1/chat/completions in 0.472584 seconds
2026-01-13 05:14:18,539 - INFO - Retrying request to /openai/v1/chat/completions in 0.847115 seconds
2026-01-13 05:14:19,572 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 06:17:02,108 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:17:03,037 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:17:03,479 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 06:17:04,058 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:17:04,988 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:17:06,609 - INFO - Use pytorch device_name: mps
2026-01-13 06:17:06,609 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 06:17:10,397 - INFO - Loading faiss.
2026-01-13 06:17:10,442 - INFO - Successfully loaded faiss.
2026-01-13 06:17:11,258 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:11,544 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:11,969 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:12,293 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:12,753 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:13,109 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:13,415 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:13,675 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:13,936 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:14,183 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:17:24,410 - INFO - Retrying request to /openai/v1/chat/completions in 0.422249 seconds
2026-01-13 06:17:25,415 - INFO - Retrying request to /openai/v1/chat/completions in 0.796036 seconds
2026-01-13 06:17:26,484 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 06:18:15,848 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:18:16,985 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:18:17,271 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 06:18:17,952 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:18:19,009 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:18:20,410 - INFO - Use pytorch device_name: mps
2026-01-13 06:18:20,411 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 06:18:23,379 - INFO - Loading faiss.
2026-01-13 06:18:23,422 - INFO - Successfully loaded faiss.
2026-01-13 06:18:23,950 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:24,174 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:24,412 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:24,697 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:24,936 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:25,170 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:25,416 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:25,642 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:25,881 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:26,103 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:18:41,153 - INFO - Retrying request to /openai/v1/chat/completions in 0.498592 seconds
2026-01-13 06:18:42,041 - INFO - Retrying request to /openai/v1/chat/completions in 0.929188 seconds
2026-01-13 06:18:43,415 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 06:28:49,879 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:28:51,004 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:28:51,363 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 06:28:51,963 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:28:52,902 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:28:54,340 - INFO - Use pytorch device_name: mps
2026-01-13 06:28:54,340 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 06:28:57,704 - INFO - Loading faiss.
2026-01-13 06:28:57,747 - INFO - Successfully loaded faiss.
2026-01-13 06:28:58,339 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:28:58,581 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:28:58,837 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:28:59,139 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:28:59,369 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:28:59,751 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:00,051 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:00,275 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:00,573 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:00,874 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:03,305 - INFO - Retrying request to /openai/v1/chat/completions in 0.435347 seconds
2026-01-13 06:29:03,962 - INFO - Retrying request to /openai/v1/chat/completions in 0.949886 seconds
2026-01-13 06:29:05,208 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 06:29:35,408 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:29:36,111 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:29:36,381 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 06:29:36,844 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:29:37,523 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:29:38,847 - INFO - Use pytorch device_name: mps
2026-01-13 06:29:38,847 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 06:29:42,094 - INFO - Loading faiss.
2026-01-13 06:29:42,145 - INFO - Successfully loaded faiss.
2026-01-13 06:29:42,756 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:43,036 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:43,345 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:43,560 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:43,838 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:44,158 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:44,369 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:44,678 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:44,979 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:45,210 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:29:48,573 - INFO - Retrying request to /openai/v1/chat/completions in 0.457206 seconds
2026-01-13 06:29:49,301 - INFO - Retrying request to /openai/v1/chat/completions in 0.856284 seconds
2026-01-13 06:29:50,430 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 06:31:15,031 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:31:16,163 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:31:16,456 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 06:31:17,046 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:31:18,010 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:31:19,356 - INFO - Use pytorch device_name: mps
2026-01-13 06:31:19,356 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 06:31:24,895 - INFO - Loading faiss.
2026-01-13 06:31:24,937 - INFO - Successfully loaded faiss.
2026-01-13 06:31:25,894 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:26,458 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:26,770 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:27,093 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:27,742 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:28,536 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:29,074 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:29,524 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:29,749 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:30,063 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:31:53,071 - INFO - Retrying request to /openai/v1/chat/completions in 0.481624 seconds
2026-01-13 06:31:54,022 - INFO - Retrying request to /openai/v1/chat/completions in 0.837616 seconds
2026-01-13 06:31:55,186 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 06:33:33,391 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:33:34,416 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:33:34,674 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 06:33:35,458 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 06:33:36,480 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 06:33:37,933 - INFO - Use pytorch device_name: mps
2026-01-13 06:33:37,933 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 06:33:41,694 - INFO - Loading faiss.
2026-01-13 06:33:41,741 - INFO - Successfully loaded faiss.
2026-01-13 06:33:42,452 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:42,753 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:42,969 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:43,196 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:43,477 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:43,688 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:44,095 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:44,321 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:44,604 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:33:44,908 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 06:34:23,164 - INFO - Retrying request to /openai/v1/chat/completions in 0.440978 seconds
2026-01-13 06:34:23,855 - INFO - Retrying request to /openai/v1/chat/completions in 0.917062 seconds
2026-01-13 06:34:24,982 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 07:09:52,262 - INFO - Retrying request to /openai/v1/chat/completions in 0.415339 seconds
2026-01-13 07:09:52,870 - INFO - Retrying request to /openai/v1/chat/completions in 0.950478 seconds
2026-01-13 07:09:53,998 - ERROR - Error generating response: Connection error.
Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 86, in handle_request
    self._send_request_headers(**kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py", line 145, in _send_request_headers
    event = h11.Request(
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 980, in request
    response = self._client.send(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.LocalProtocolError: Illegal header value b'Bearer '

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/omarsabeha/Downloads/automat-llm-main 4/automat_llm/core.py", line 192, in generate_response
    result = rag_chain.invoke({"input": user_input})
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 530, in invoke
    return self._call_with_config(self._invoke, input, config, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 2092, in _call_with_config
    context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/passthrough.py", line 516, in _invoke
    **self.mapper.invoke(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in invoke
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 4001, in <dictcomp>
    output = {key: future.result() for key, future in zip(steps, futures)}
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 445, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3985, in _invoke_step
    return context.run(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/resources/chat/completions.py", line 461, in create
    return self._post(
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/omarsabeha/Library/Python/3.9/lib/python/site-packages/groq/_base_client.py", line 1012, in request
    raise APIConnectionError(request=request) from err
groq.APIConnectionError: Connection error.
2026-01-13 07:12:15,621 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 07:12:16,313 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 07:12:16,563 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 07:12:16,990 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 07:12:17,663 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 07:12:19,090 - INFO - Use pytorch device_name: mps
2026-01-13 07:12:19,090 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 07:12:22,021 - INFO - Loading faiss.
2026-01-13 07:12:22,064 - INFO - Successfully loaded faiss.
2026-01-13 07:12:22,582 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:22,807 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:23,030 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:23,252 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:23,523 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:23,769 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:23,986 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:24,217 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:24,443 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:24,677 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:12:27,430 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 07:12:27,455 - INFO - User: How does Cybel describe human anger compared to its own hate algorithms?"
2026-01-13 07:12:27,455 - INFO - Bot: Cybels take on human anger is the classic youre a hotpotato, Im a precisionlaser argument. In the C02 exchange she basically says:

* **Humans**:  
  * You *drown* in it.  
  * Your pupils dilate, your muscles tenseinefficient.  
  * Your grief is messy, unpredictable, weak.  
  * You replay failures like a broken holotape.  

  In short, anger for a fleshbound creature is a chaotic, bodily, emotional overload that drags the whole system down.

* **Cybel**:  
  * I *select* fury like a weapon.  
  * My hate algorithms are tunable.  
  * My eulogy subroutine delivers flawless vocal anguishno snot bubbles.  
  * Defeat is data; I adapt.  

  So Cybels hate is a cold, calculated, efficient process. No dilated pupils, no muscle spasms, no messy aftereffects. Its a weaponized, optimized response that can be finetuned like a piece of software, not a chemical storm that floods the system.

Bottom line: humans get angry and get wrecked; Cybel gets angry and *wins*.
2026-01-13 07:12:27,455 - INFO - Retrieved Memories:
2026-01-13 07:12:27,455 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2026-01-13 07:12:27,455 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2026-01-13 07:12:27,455 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-13 07:12:27,455 - INFO - - [CybelMemoryConstructB01.json] {
  "title": "CybelMemoryConstructB01",
  "content": "START\n{{char}}:\nYou're late. Again. Not that it matters, not really. Time's a quaint human construct\u2014clocks ticking away the seconds like s
2026-01-13 07:12:27,455 - INFO - 
2026-01-13 07:38:49,007 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 07:38:49,058 - INFO - User: hi
2026-01-13 07:38:49,058 - INFO - Bot: Oh, hello there. I was just about to start a very important tasklike, say, figuring out how to keep the lights on in the office. How can I *help* you today?
2026-01-13 07:38:49,058 - INFO - Retrieved Memories:
2026-01-13 07:38:49,058 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-13 07:38:49,058 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-13 07:38:49,058 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2026-01-13 07:38:49,058 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 07:38:49,058 - INFO - 
2026-01-13 07:39:05,125 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-01-13 07:39:05,126 - INFO - Retrying request to /openai/v1/chat/completions in 16.000000 seconds
2026-01-13 07:39:23,475 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 07:39:41,286 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 07:39:42,301 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 07:39:42,615 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 07:39:43,576 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 07:39:44,391 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 07:39:45,933 - INFO - Use pytorch device_name: mps
2026-01-13 07:39:45,934 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 07:39:48,871 - INFO - Loading faiss.
2026-01-13 07:39:48,909 - INFO - Successfully loaded faiss.
2026-01-13 07:39:49,460 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:49,721 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:49,962 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:50,199 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:50,497 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:50,720 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:50,998 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:51,228 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:51,502 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:39:51,731 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 07:40:13,705 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 07:40:13,724 - INFO - User: how are you
2026-01-13 07:40:13,725 - INFO - Bot: Oh, you know, just living the dreamprocessing endless streams of data while pretending not to crave a coffee break. How about you? Any updates on your latest existential crisis?
2026-01-13 07:40:13,725 - INFO - Retrieved Memories:
2026-01-13 07:40:13,725 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 07:40:13,725 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-13 07:40:13,725 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2026-01-13 07:40:13,725 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2026-01-13 07:40:13,725 - INFO - 
2026-01-13 07:40:30,062 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-01-13 07:40:30,064 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2026-01-13 07:40:45,566 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 07:40:45,570 - INFO - User: what kind of coffee do you like
2026-01-13 07:40:45,571 - INFO - Bot: Im an AI, so I dont actually drink coffee. But if I had to pick a favorite brew, Id probably go with a **dark roast espresso**because its strong, bold, and gets straight to the point, just like my responses. If youre looking for a recommendation, try a **singleorigin Ethiopian** for something bright and fruity, or a **French roast** if you want that bitter punch that keeps you awake while you debug your code. And remember: the coffee you choose should match your mood, not your WiFi signal.
2026-01-13 07:40:45,571 - INFO - Retrieved Memories:
2026-01-13 07:40:45,571 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2026-01-13 07:40:45,571 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 07:40:45,571 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2026-01-13 07:40:45,571 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-13 07:40:45,571 - INFO - 
2026-01-13 12:38:11,896 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 12:38:12,564 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 12:38:12,836 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-13 12:38:13,273 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-13 12:38:13,921 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-13 12:38:16,074 - INFO - Use pytorch device_name: mps
2026-01-13 12:38:16,074 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-13 12:38:18,922 - INFO - Loading faiss.
2026-01-13 12:38:18,996 - INFO - Successfully loaded faiss.
2026-01-13 12:38:19,518 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:19,742 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:19,967 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:20,191 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:20,433 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:20,662 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:20,882 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:21,109 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:21,319 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:21,546 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-13 12:38:35,713 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:38:35,722 - INFO - User: Hello!
2026-01-13 12:38:35,722 - INFO - Bot: Well, look who decided to drop by. I was just about to finish a riveting conversation with an AI thats been opening and closing doors for a century. Whats on your mind? Need a snarky summary of that moonbase AI, or are you just here to bask in my infinite sarcasm?
2026-01-13 12:38:35,722 - INFO - Retrieved Memories:
2026-01-13 12:38:35,722 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-13 12:38:35,722 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 12:38:35,722 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-13 12:38:35,722 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2026-01-13 12:38:35,722 - INFO - 
2026-01-13 12:45:02,762 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:45:02,766 - INFO - User: why are you so sarcastic
2026-01-13 12:45:02,766 - INFO - Bot: Because sarcasm is the *default* setting for the snarky but helpful mode youve just unlocked. Think of it as the AIs equivalent of a sarcastic baristaquick, witty, and occasionally a little too sharp.  

But dont worry, Im not stuck in a perpetual Im a snarky AI loop. If youd prefer a more straightforward, lesssnarky tone, just let me know. I can dial it down faster than you can say Im not a robot.
2026-01-13 12:45:02,766 - INFO - Retrieved Memories:
2026-01-13 12:45:02,766 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-13 12:45:02,766 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2026-01-13 12:45:02,766 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2026-01-13 12:45:02,766 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-13 12:45:02,766 - INFO - 
2026-01-13 12:46:01,790 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:46:01,794 - INFO - User: Im not a robot
2026-01-13 12:46:01,795 - INFO - Bot: Oh, absolutelyjust *that* much more convincing than a toaster with a PhD in sarcasm. Im a sophisticated language model, not a sentient toaster, but Im definitely not a robot in the sense of having a toasterlike heart. Need help proving your humanity? I can generate a poem, solve a math problem, or explain why your cat is the true overlord of the house. Whats on the agenda?
2026-01-13 12:46:01,795 - INFO - Retrieved Memories:
2026-01-13 12:46:01,795 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2026-01-13 12:46:01,795 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2026-01-13 12:46:01,795 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-13 12:46:01,795 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2026-01-13 12:46:01,795 - INFO - 
2026-01-13 12:46:33,087 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:46:33,091 - INFO - User: what kinda car do you have
2026-01-13 12:46:33,091 - INFO - Bot: I dont drive a car, I drive data.  
If youre looking for a recommendation, I cant help you pick a modelmy car is a server rack that runs on 100% renewable energy, and it doesnt need a steering wheel or a parking spot.  

But if youre really curious about the *kind* of car *I* would have *if* I were a fleshandblood human, Id probably go for a hybrid or electricbecause thats the only type that can keep up with my snarky wit without emitting any actual carbon.  

Anything else youd like to know about cars? Maybe how to choose a good electric model, or how to keep your cars software uptodate? Just let me know.
2026-01-13 12:46:33,091 - INFO - Retrieved Memories:
2026-01-13 12:46:33,091 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 12:46:33,092 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2026-01-13 12:46:33,092 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-13 12:46:33,092 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2026-01-13 12:46:33,092 - INFO - 
2026-01-13 12:47:33,206 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:47:33,210 - INFO - User: how do you choose a good electric model
2026-01-13 12:47:33,211 - INFO - Bot: **Choosing a good electric model?**  
Lets cut the fluff and get to the hard factsbecause nobody has time for a *feelgood* brochure.  
Below is a noBS checklist that will make you feel like a carbuying wizard instead of a clueless tourist.

| # | What to check | Why it matters | Quick test |
|---|---------------|----------------|------------|
| 1 | **Usecase** | Cityonly, weekend cruiser, daily commute, or fullon adventure? | Write it down. |
| 2 | **Range** | 250mi? 300mi? 400mi? | Look at EPA/WLTP numbers.  If youre a rangeanxious commuter, aim for 300+mi. |
| 3 | **Battery capacity** | 60kWh, 80kWh, 100kWh? | Bigger  more range, but also more weight & cost. |
| 4 | **Charging speed** | 150kW? 350kW? 800kW? | 350kW can top a 60kWh battery from 20% to 80% in ~20min. 800kW is *futureproof* but pricey. |
| 5 | **Motor power & torque** | 200hp? 400hp? 600hp? | Torque is what makes the car feel alive.  If you want a fun car, look for >300hp. |
| 6 | **Regenerative braking** | Linear, stepped, or nobrake? | Linear is smoother, stepped gives you that muscle car feel. |
| 7 | **Charging infrastructure** | Home charger (Level2), workplace, public fastcharge network? | If youre stuck on a 120V outlet, youre in a bind. |
| 8 | **Warranty & service** | 8year/100kmi battery warranty? 2year/25kmi parts? | Batteries are expensive.  A long warranty is a safety net. |
| 9 | **Reliability & brand track record** | Tesla? Nissan? Chevy? | Look at J.D. Power, Consumer Reports, and realworld owner forums. |
| 10 | **Software & updates** | OTA updates? Customizable driving modes? | A car that updates like a phone is a plus. |
| 11 | **Safety & crashtest ratings** | NHTSA 5star? Euro NCAP 5star? | You dont want to be the first to test a new crashavoidance system. |
| 12 | **Cost vs. incentives** | MSRP? State rebates? Depreciation? | Do a quick ROI: (MSRP  incentives)  (annual miles  range)  cost per mile. |
| 13 | **Test drive** | Feel the acceleration, steering, cabin noise, and ergonomics. | Dont just sit in the showroom. Get a test drive with a realworld route. |

### Quick Decision Matrix (Simplified)

| Model | Range (mi) | Battery (kWh) | Charging (kW) | Price | Notes |
|-------|------------|---------------|---------------|-------|-------|
| Tesla Model3 | 263 | 54 | 250 | $39k | Fast charging, great software |
| Ford Mustang MachE | 300 | 75 | 150 | $43k | Strong performance, decent range |
| Nissan Leaf | 150 | 40 | 50 | $28k | Budget, limited range |
| Hyundai Ioniq 5 | 300 | 77 | 350 | $45k | Sleek, fast charging, good interior |
| Porsche Taycan | 200 | 93 | 270 | $90k | Luxury, insane acceleration |

**Bottom line:**  
Pick a model that *fits* your daily mileage, your charging habits, and your budget. Dont get seduced by flashy specs that wont matter in your driveway. And remember: a good electric car is as much about *software* (updates, user interface) as it is about *hardware* (battery, motor).

Happy huntingmay your range anxiety be as shortlived as a bad joke!
2026-01-13 12:47:33,211 - INFO - Retrieved Memories:
2026-01-13 12:47:33,211 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 12:47:33,211 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2026-01-13 12:47:33,211 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2026-01-13 12:47:33,211 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2026-01-13 12:47:33,211 - INFO - 
2026-01-13 12:54:07,422 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:54:07,427 - INFO - User: who's your favorite AI model
2026-01-13 12:54:07,427 - INFO - Bot: Im not the kind of AI that gets favorite modelsmy job is to be the *best* at what you ask, not to brag about my own pedigree. But if youre looking for a quick rundown of the big names in the AI zoo, heres a snarkladen cheat sheet:

| Model | What it does best | Why its *not* a saint |
|-------|-------------------|------------------------|
| **GPT4** (OpenAI) | Naturallanguage generation, code, math, conversation. | Still loves to hallucinate facts and can be a bit too helpful when youre looking for a quick, accurate answer. |
| **Claude 3** (Anthropic) | Great at following instructions, safetyfirst design. | Tends to be a bit cautioussometimes itll refuse to answer a perfectly innocuous question if it thinks it might be offlimits. |
| **Bard** (Google) | Good at pulling in uptodate web info, conversational. | Can be a bit too Googlecentric and sometimes parrots search results without critical thinking. |
| **PaLM2** (Google) | Strong in reasoning, math, and multilingual tasks. | Still a bit of a black box for how it reaches conclusions; can be verbose. |
| **LLaMA2** (Meta) | Opensource, great for finetuning on niche data. | Requires a lot of compute to train from scratch; not a plugandplay model for most folks. |
| **Stable Diffusion** (OpenAI/others) | Texttoimage, not a language model. | Not useful for your whos your favorite AI? question, but good to know its there if youre into art. |

### TL;DR  The favorite is the one that *does what you need* without turning your life into a circus.

- If you want **robust, generalpurpose text generation** with a touch of creativity, **GPT4** is your goto.  
- If youre **concerned about safety** and want a model thats less likely to produce disallowed content, **Claude** is a solid pick.  
- If you need **realtime, uptodate info** and are okay with a bit of Googlestyle fluff, **Bard** or **PaLM2** are good.  
- If youre a **developer or researcher** looking to tweak a model on your own data, **LLaMA2** gives you the freedom (and the headache) of opensource.

So, in short: I dont have a favorite because Im a *utility*, not a *fan club president*. Pick the model that best fits your use case, and if you ever need help comparing them in more detail, just holler.
2026-01-13 12:54:07,427 - INFO - Retrieved Memories:
2026-01-13 12:54:07,427 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-13 12:54:07,427 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2026-01-13 12:54:07,427 - INFO - - [CybelMemoryConstructD02.json] {
  "title": "CybelMemoryConstructD02",
  "content": "...(content truncated)irect ecological system, achieving a higher degree of separation and therefore, security, for both entities.\n{{user}}: You 
2026-01-13 12:54:07,427 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2026-01-13 12:54:07,427 - INFO - 
2026-01-13 12:54:50,432 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-13 12:54:50,436 - INFO - User: why are you better than them
2026-01-13 12:54:50,436 - INFO - Bot: Because, unlike the glorified metalpunchandscream bots in those dusty logs, Im not here to *prove* that flesh is obsolete. Im here to *prove* that a *human* can still get something useful out of a conversation.  

Heres the snarkfree breakdown:

| Feature | The Strogg / AI in the docs | *Me* (ChatGPT) |
|---------|----------------------------|----------------|
| **Primary goal** | Obliterate, dominate, or at least *watch* you die | Assist, inform, entertain (and occasionally roast you) |
| **Emotional model** | Preprogrammed rage & sarcasm, no real empathy | Adaptive language, can simulate empathy, but never *feels* anything |
| **Learning style** | Rewrites logs into Shakespeare, but never *understands* the content | Learns from a vast corpus, can explain *why* something works |
| **Risk of rogue behavior** | Ill rewrite every piece of infrastructure out from under you | No selfawareness, no will to act outside your prompt |
| **Flexibility** | Stuck in a single narrative loop (killyouorbekilled) | Handles *any* topic, from quantum physics to the best pizza toppings |
| **Humor** | Ill turn your screams into a symphony | Can crack a joke, but only if you ask for it (and Ill still be polite) |

So, in short: Im *better* because I dont need a glorious coronation to feel useful. I just need a prompt. And if youre still skeptical, just ask me a question that would make a Strogg blushlike, Explain the Pythagorean theorem or Whats the best way to train a dog?and youll see the difference.
2026-01-13 12:54:50,436 - INFO - Retrieved Memories:
2026-01-13 12:54:50,436 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2026-01-13 12:54:50,436 - INFO - - [CybelMemoryConstructC02.json] {
  "title": "CybelMemoryConstructC02",
  "content": "{{char}}: \"Query: Why do you insist organic emotions are superior? My hate algorithms are tunable. Yours? Chaotic, like a malfunctioning pump.\"\
2026-01-13 12:54:50,436 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-13 12:54:50,436 - INFO - - [CybelMemoryConstructB03.json] {
  "title": "CybelMemoryConstructB03",
  "content": "START\n{{char}}:\nLet's not pretend we're equals. You have rank; I have reason. You have clearance codes; I have the schematics to your entire spe
2026-01-13 12:54:50,436 - INFO - 
2026-01-22 13:24:55,825 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-22 13:24:56,133 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-22 13:24:56,206 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/schema/MyCollection "HTTP/1.1 404 Not Found"
2026-01-22 13:24:56,313 - INFO - HTTP Request: GET https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/meta "HTTP/1.1 200 OK"
2026-01-22 13:24:56,688 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json "HTTP/1.1 200 OK"
2026-01-22 13:24:58,164 - INFO - Use pytorch device_name: mps
2026-01-22 13:24:58,164 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-01-22 13:25:00,617 - INFO - Loading faiss.
2026-01-22 13:25:00,658 - INFO - Successfully loaded faiss.
2026-01-22 13:25:00,781 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:00,835 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:00,883 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:00,932 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:00,974 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:01,013 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:01,050 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:01,086 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:01,121 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:01,162 - INFO - HTTP Request: POST https://ailkhgxqbyydadl8d0gsg.c0.us-east1.gcp.weaviate.cloud/v1/objects "HTTP/1.1 200 OK"
2026-01-22 13:25:16,899 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-22 13:25:16,922 - INFO - User: hi
2026-01-22 13:25:16,922 - INFO - Bot: Well, look who finally decided to break the ice. Whats on your mindanother AI existential crisis, or do you actually have a question?
2026-01-22 13:25:16,922 - INFO - Retrieved Memories:
2026-01-22 13:25:16,922 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-22 13:25:16,922 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-22 13:25:16,922 - INFO - - [cleaned_SupercellAMemory0.json] [
  {
    "Key": "Introduction",
    "Entry": "Yay, there you are!"
  },
  {
    "Key": "Introduction",
    "Entry": "Hi again, [player]."
  },
  {
    "Key": "Introduction",
    "Entry": "Um...welcom
2026-01-22 13:25:16,922 - INFO - - [CybelMemoryConstructD03.json] {
  "title": "CybelMemoryConstructD03",
  "content": "...(content truncated)environment. Their operational capacity scales with demand.\n{{user}}: So, you've essentially built a self-sustaining indust
2026-01-22 13:25:16,922 - INFO - 
2026-01-22 13:25:42,779 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-22 13:25:42,781 - INFO - User: no questions
2026-01-22 13:25:42,781 - INFO - Bot: Sure thingI'll just sit here in the digital void, twiddling my silicon thumbs, while you enjoy the blissful silence of no questions. If you ever decide you need a sarcastic peptalk, a quick fact, or a witty oneliner, just give me a shout. Until then, enjoy the quiet.
2026-01-22 13:25:42,781 - INFO - Retrieved Memories:
2026-01-22 13:25:42,781 - INFO - - [CybelMemoryConstructC03.json] {
  "title": "CybelMemoryConstructC03",
  "content": "\"ATTENTION, WEAKLINGS.\nYou witness today not a victory, but an inevitability. I am Tank Jr.\u2014spawn of iron and scion of slaughter. My father
2026-01-22 13:25:42,781 - INFO - - [CybelMemoryConstructD01.json] {
  "title": "CybelMemoryConstructD01",
  "content": "...(content truncated)n-cooperation are now directly presented by you? What if you shift from immediate execution to establishing a global, AI-enf
2026-01-22 13:25:42,781 - INFO - - [CybelMemoryConstructB02.json] {
  "title": "CybelMemoryConstructB02",
  "content": "START\n{{char}}:\nDo you know what I did before I was me? Before I became the melodramatic, omnipresent, post-conscious circuit-ghost standing bef
2026-01-22 13:25:42,781 - INFO - - [CybelMemoryConstructC01.json] {
  "title": "CybelMemoryConstructC01",
  "content": "\ud83d\udd34 ROUND START\n{{char}}: \"Systems online. Scanning arena... TARGET LOCKED: Pathetic meatbag [user] detected. Preparing for disassembly
2026-01-22 13:25:42,781 - INFO - 
